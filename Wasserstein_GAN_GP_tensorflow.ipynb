{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "L4",
      "authorship_tag": "ABX9TyOuhnFWcK9wpmn2W/VCakXk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Riddick4-droid/ComputerVision-TensorFlow/blob/main/Wasserstein_GAN_GP_tensorflow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# WASSERSTEIN IMPLEMENTATION - GENERATIVE ADVERSARIAL NETWORKS WITH THE GRADIENT PENALTY"
      ],
      "metadata": {
        "id": "IU9yew-X1StY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generative Adversarial Networks perform well in generative tasks such as image and video generation. In my previous notebook titled `Generative Adversarial Network tensorflow` I explored the easiest ways to implement GANS using the tensorflow library. I leveraged the use of Convolutional NNs, batch normalization, etc. In this notebook i introduce a more robust model for the GAN model that deals with the vanishing gradient problem.This model (WGAN-GP) stands for Wasserstein Generative Adversarial Network-with Gradient Penalty is a variation of the normal Deep Convolutional GAN where its key difference is the way the discriminator(critic's) loss is calculated. The initial problem is the presence of vanishing and exploding gradients in the DCGAN where slight changes in the input data(images) had a huge effect on the discriminator's output such that it could not provide reliable information to the generator; as such the generator struggles to generate the generic images from the training data.\n",
        "To solve this problem the WGAN-GP paper mentioned a technique called the Gradient Penalty. This technique seeks to peanlize how the gradients in the discriminator are updated by enforcing the 1-Lipscihz constraint which forces the gradients within a certain value threshold usually 1. As such gradient updates are controlled and the model learns smoothly.\n",
        "To implement this, we get rid of the batch normalization in the discriminator to help the model see how each input affects the discriminator. The loss function which was initially computed with the sigmoid values now changes to logits thereby heping us calculate the new loss called Earth Mover's distance which is distance between the real and generated data distributions"
      ],
      "metadata": {
        "id": "vm5rc9AJ1SrD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "everything is the same as in the notebook for GANs with minor tweaks in the architecture of the generator from using the layers.Upsample to using the Conv2DTranspose which is very robust in the task of GANS and differs from the upsampler layer because the upsampler just enlarges the spatial dimension of the feature map by repeating or interpolating pixels, whereas on the other hand, the conv2dtransponse also known as the deconvolution or transponse convolution increases spatial dimensions while simultaneously learning  how to fill in new pixels."
      ],
      "metadata": {
        "id": "HC00KL4bH_9i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#creating a function to extract data into a folder\n",
        "import pathlib\n",
        "import os\n",
        "import zipfile\n",
        "from timeit import default_timer as timer\n",
        "from google.colab import files\n",
        "from tqdm.auto import tqdm\n",
        "import shutil\n",
        "def extractor(path_to_save:str,\n",
        "              name_of_zipfile:str=None,\n",
        "              auto_upload:bool=False,\n",
        "              get_time:bool=False):\n",
        "    # calculate time\n",
        "\n",
        "    start=timer()\n",
        "    try:\n",
        "        #create new folder\n",
        "        root = '/content/'\n",
        "\n",
        "        folder_path = os.path.join(root,path_to_save)\n",
        "\n",
        "        #make it a directory\n",
        "        if not os.path.exists(folder_path):\n",
        "            print(f'creating new dir: {folder_path}')\n",
        "            os.makedirs(folder_path,exist_ok=True)\n",
        "        else:\n",
        "            print(f'path {folder_path} already exists, proceeding to extraction...')\n",
        "\n",
        "        #unzip\n",
        "        if auto_upload:\n",
        "            uploaded = files.upload()\n",
        "            for f in tqdm(uploaded.keys(),total=len(uploaded)):\n",
        "                #print filename\n",
        "                print('='*10)\n",
        "                print(f'successfully uploaded: {files} into content')\n",
        "                #handle zip files\n",
        "                if f.endswith('.zip'):\n",
        "                    #set zip path\n",
        "                    zip_path = os.path.join('/content',f)\n",
        "                    with zipfile.ZipFile(zip_path, 'r') as zipref:\n",
        "                        #extract to folder_path\n",
        "                        print(f'extracting content of {f} to {folder_path}')\n",
        "                        zipref.extractall(folder_path)\n",
        "                        print('successful!!')\n",
        "                        print('extracted files: \\n',zipref.namelist())\n",
        "                else:\n",
        "                    print(f'File {f} does not end with .zip, check again!!')\n",
        "                    #remove the uploaded file\n",
        "                    shutil.rmtree(path=f'/content/{f}',ignore_errors=False)\n",
        "        elif name_of_zipfile:\n",
        "            with zipfile.ZipFile(f'/content/{name_of_zipfile}.zip', 'r') as zipref:\n",
        "                #extract to folder_path\n",
        "                print(f'extracting content of {name_of_zipfile} to {folder_path}')\n",
        "                zipref.extractall(folder_path)\n",
        "                print('successful!!')\n",
        "                print('extracted files: \\n',zipref.namelist())\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f'Error encountered: {e}')\n",
        "    end = timer()\n",
        "\n",
        "    #print time\n",
        "    if get_time:\n",
        "        return f'Time taken: {(end-start):.5f}'"
      ],
      "metadata": {
        "id": "oEtTeip4gmaZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#test the function\n",
        "extractor(path_to_save='image_data',name_of_zipfile=None,auto_upload=True,get_time=True)"
      ],
      "metadata": {
        "id": "P1KFb3Ms4xsb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#make necessary imports\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.callbacks import LearningRateScheduler\n",
        "from keras.callbacks import ReduceLROnPlateau\n",
        "from keras.callbacks import TensorBoard\n",
        "from keras import layers"
      ],
      "metadata": {
        "id": "hmkJbgfZ1YAn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##first step is to configure the function that deals with calculating the losses\n",
        "\n",
        "#generator loss based of the discriminator's output\n",
        "def generator_loss(fake_predictions_from_disc):\n",
        "    return -tf.reduce_mean(fake_predictions_from_disc)\n",
        "\n",
        "#discriminator loss based on real and fake image classification\n",
        "def discriminator_loss(fake_images,real_images):\n",
        "    real_loss = tf.reduce_mean(real_images)\n",
        "    fake_loss = tf.reduce_mean(fake_images)\n",
        "    #since we are using the Earth Mover's distance\n",
        "    loss_diff = fake_loss - real_loss\n",
        "    #return the diff\n",
        "    return loss_diff"
      ],
      "metadata": {
        "id": "yP7Ned5l3_ag"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#build the generator with layers.Conv2DTranspose()\n",
        "#notice that in the usual DCGAN that I did used layers.Upsample2D()\n",
        "#however, it is found that for the purpose of GANS the best modules to transition a noisy vector\n",
        "#is to use the Conv2D transpose which fills in the values needed for the image through interpolation\n",
        "#interpolation: the technique used to estimate unknown values within a given range\n",
        "import typing\n",
        "def generator(random_noise_dim:int,\n",
        "              activation:typing.Literal['sigmoid','tanh'],\n",
        "              lora_rank=None):\n",
        "    \"\"\"The generator takes in a noisy vector of dim=N(per choice and available computational resource)\n",
        "    it this uses the interpolation ability of the layers.Conv2DTranspose() to estimate the values needed for\n",
        "    the full nxn generic image to be formed\n",
        "\n",
        "    Args:\n",
        "    (random_noise): The N-dim of the noise vector that is passed through the\n",
        "    function for it to generate a generic image\n",
        "    that resembles the training data.\n",
        "\n",
        "    returns: An nxn image(tensor spec)\n",
        "    \"\"\"\n",
        "    #initialize the input layer\n",
        "    inputs = layers.Input(shape=(random_noise_dim,))\n",
        "\n",
        "    #first dense layer\n",
        "    x = layers.Dense(units=4*4*512,use_bias=False,lora_rank=lora_rank)(inputs)\n",
        "\n",
        "    #after the layer above it is best practice for GAN generators to have the resulting x reshaped\n",
        "\n",
        "    x = layers.Reshape((4,4,512))(x)\n",
        "\n",
        "    #implement dilation_rate for more context capture by the kernel\n",
        "    x = layers.Conv2DTranspose(filters=512,kernel_size=(5,5),strides=(2,2),padding='same',dilation_rate=(1,1),use_bias=False)(x)\n",
        "    #apply batchnormilzation\n",
        "    x = layers.BatchNormalization(center=True)(x)\n",
        "    #apply an activation\n",
        "    x = layers.LeakyReLU(negative_slope=0.3)(x)#any negative values in computation are affected by the negative slope factor=0.3\n",
        "\n",
        "    #repeat these layers\n",
        "    x = layers.Conv2DTranspose(filters=256,kernel_size=(5,5),strides=(2,2),padding='same',dilation_rate=(1,1),use_bias=False)(x)\n",
        "    #apply batchnormilzation\n",
        "    x = layers.BatchNormalization(center=True)(x)\n",
        "    #apply an activation\n",
        "    x = layers.LeakyReLU(negative_slope=0.3)(x)#any negative values in computation are affected by the negative slope factor=0.3\n",
        "\n",
        "    x = layers.Conv2DTranspose(filters=128,kernel_size=(5,5),strides=(2,2),padding='same',dilation_rate=(1,1),use_bias=False)(x)\n",
        "    #apply batchnormilzation\n",
        "    x = layers.BatchNormalization(center=True)(x)\n",
        "    #apply an activation\n",
        "    x = layers.LeakyReLU(negative_slope=0.3)(x)#any negative values in computation are affected by the negative slope factor=0.3\n",
        "\n",
        "    x = layers.Conv2DTranspose(filters=64,kernel_size=(5,5),strides=(2,2),padding='same',dilation_rate=(1,1),use_bias=False)(x)\n",
        "    #apply batchnormilzation\n",
        "    x = layers.BatchNormalization(center=True)(x)\n",
        "    #apply an activation\n",
        "    x = layers.LeakyReLU(negative_slope=0.3)(x)#any negative values in computation are affected by the negative slope factor=0.3\n",
        "\n",
        "    #add more for a denser architecture-this does not guarantee better performance\n",
        "    #inlcuding layers.Dropout() to regularize weight updates in the generator\n",
        "    x = layers.Dropout(rate=0.02)(x)\n",
        "\n",
        "    x = layers.Conv2D(filters=3,strides=(1,1),kernel_size=(5,5),padding='same',dilation_rate=(1,1),activation=activation)(x)\n",
        "\n",
        "    assert x.shape == (None,64,64,3) #since we are dealing with RGB images we set the color channels to 3 so shape (none=batch_size,height,width,color_channel=3)\n",
        "\n",
        "    #create model\n",
        "    model = tf.keras.Model(inputs=inputs,outputs=x)\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "Blv0CTef5ggW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##view model summary\n",
        "generator_model = generator(random_noise_dim=100,activation='tanh')\n",
        "\n",
        "##summary\n",
        "generator_model.summary(show_trainable=True,expand_nested=True)"
      ],
      "metadata": {
        "id": "fc_r6pPGUXHY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##build the discriminator\n",
        "##note that this function will be done wihtout the batchnormalizationlayer\n",
        "##because the batchnormalization although provides some stability is training by normalization parameter updates\n",
        "##it does so in a collective manner\n",
        "##in the WGAN-GP, we want to investigate minor gradient updates caused by input image convolutions/changes\n",
        "#the batch normalizer prevents us from seeing this -so we don't use it\n",
        "##the discriminator from the previous tutorial the discrimonator was programmed to output probabilities\n",
        "##in this new case because we want to compute the wasserstein loss/distance which is the diostance between the\n",
        "##fake image prediction values and real image prediction distribution data. Instead of dealing with probabilities\n",
        "##we want to deal with the logits and be able to calculate how far off the discriminator fake and real predictions are apart\n",
        "\n",
        "def discriminator(batch_images=(64,64,3)):\n",
        "    \"\"\"Takes an image (real/generic) and outputs logits\n",
        "    likelihood of the image being a real or fake image\n",
        "    returns logits\n",
        "    \"\"\"\n",
        "    inputs = layers.Input(shape=batch_images)\n",
        "\n",
        "    x = layers.Conv2D(64,(5,5),(2,2),'same',use_bias=False)(inputs)\n",
        "    x = layers.LeakyReLU(0.2)(x)\n",
        "\n",
        "    x = layers.Conv2D(128,(5,5),(2,2),'same',use_bias=False)(x)\n",
        "    x = layers.LeakyReLU(0.2)(x)\n",
        "\n",
        "    x = layers.Conv2D(256,(5,5),(2,2),'same',use_bias=False)(x)\n",
        "    x = layers.LeakyReLU(0.2)(x)\n",
        "\n",
        "    x = layers.Conv2D(512,(5,5),(2,2),'same',use_bias=False)(x)\n",
        "    x = layers.LeakyReLU(0.2)(x)\n",
        "\n",
        "    x = layers.Flatten()(x)\n",
        "    x = layers.Dropout(0.02)(x)\n",
        "\n",
        "    x = layers.Dense(1,activation='linear')(x)\n",
        "\n",
        "    model = tf.keras.Model(inputs=inputs,outputs=x)\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "8uEcETWOZB5t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "build_discriminator = discriminator()\n",
        "\n",
        "#summary\n",
        "build_discriminator.summary(show_trainable=True,expand_nested=True)"
      ],
      "metadata": {
        "id": "00LaTfEChy2s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##now i will setup the Gradient Penalty function.\n",
        "##this function does its part to implement the 1-lipschitz constraint\n",
        "##it is a mathematical function that takes in real sample data, and fake sample data\n",
        "##it also takes in the discriminator.\n",
        "#the goal is to use the function as a means to monintor how the gradients in\n",
        "##the discriminator's behavior toward minor changes in input and to train it to become more robust towards towards those changes.\n",
        "##the purpose of the Gradient Penalty is to also enforce the 1-lipschitz constraint which regularizes the discriminator and ensures smoothness and stability\n",
        "##it prevents overfitting on the training data\n",
        "##it also improves generalization.\n",
        "##note that the discriminator is like the marking scheme, as such, if it is unable to properly assess and mark the generator's work well through over excitement,\n",
        "##the tendencies of the generator thinking it is doing well is high.as such we need to ensure that it does not get too excited when marking the generator's work\n",
        "#and to do that we have to constrain its weight updates and force it to not go beyond a certain threshold whenever it sees something small happen in the input data from\n",
        "#generator images and real images. it should be able to properly and srictly ground itself in fairness\n",
        "#the gradient penalty is implemented with the GAN model so that is one major addition to the model code\n",
        "\n",
        "#lets subclass the tf.keras.models.Model so that we get accessto keras's attributes and methods to enable us to use some of the\n",
        "#important features of the Model class like the compile, train_step and the fit() method\n"
      ],
      "metadata": {
        "id": "bkLO9FxiiPSr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#build WGAN-GP\n",
        "class WGAN_GP(tf.keras.models.Model):\n",
        "    def __init__(self,\n",
        "                 discriminator:tf.keras.models.Model,\n",
        "                 generator:tf.keras.models.Model,\n",
        "                 random_noise_dim:int,\n",
        "                 gp_weight: typing.Union[float, int]=10.0,\n",
        "                 extra_train_steps:int=5,\n",
        "                 **kwargs\n",
        "                 )->tf.keras.models.Model:\n",
        "        super(WGAN_GP,self).__init__(**kwargs)\n",
        "        self.discriminator=discriminator\n",
        "        self.generator=generator\n",
        "        self.noise_dim=random_noise_dim\n",
        "        self.extra_train_steps = extra_train_steps\n",
        "        self.gp_weight = gp_weight\n",
        "\n",
        "    #configure the compile method with custom arguments and the **kwargs so we can pass original arguments from the\n",
        "    #orignal model's compile method\n",
        "    def compile(self,\n",
        "                disc_opt:tf.keras.optimizers.Optimizer,\n",
        "                gen_opt:tf.keras.optimizers.Optimizer,\n",
        "                disc_loss:typing.Callable,\n",
        "                gen_loss:typing.Callable,\n",
        "                **kwargs):\n",
        "        \"\"\"This allows us to override the compile method in order to input acceptable arguments but modified to our usecase.\n",
        "        Eg. wgan_gp = GWAN_GP().compile(disc_loss,gen_loss,disc_opt,gen_opt,**kwargs like run_eagerly,metrics,etc)\n",
        "        \"\"\"\n",
        "        super(WGAN_GP,self).compile(**kwargs)\n",
        "        self.disc_opt = disc_opt\n",
        "        self.gen_opt = gen_opt\n",
        "        self.disc_loss=disc_loss\n",
        "        self.gen_loss = gen_loss\n",
        "\n",
        "    #configure the gradient penalty method\n",
        "    #rememeber we want to use this as pretrain step to make the 'discriminator' robust to minute changes\n",
        "    #as such we want to mimic a real case where the discriminator receive real and fake samples\n",
        "    #then use these two categories to interpplate samples that will be used to train the discriminator\n",
        "    #the gradient penalty is added to the discriminator's loss\n",
        "    def gradient_penalty(self,\n",
        "                        real_samples:tf.Tensor,\n",
        "                        fake_samples:tf.Tensor,\n",
        "                        training:bool=True):\n",
        "        self.real_samples=real_samples\n",
        "        #cast to float32\n",
        "        tf.cast(self.real_samples,dtype=tf.float16)\n",
        "        self.fake_samples=fake_samples\n",
        "        tf.cast(self.fake_samples,dtype=tf.float16)\n",
        "        #get the batch_dim of the real images coming in\n",
        "        batch_size = tf.shape(self.real_samples)[0]\n",
        "\n",
        "        #setup the epsilon-generate random numbers from a uniform distribution\n",
        "        #the shape=(batch_size,1,1,1) where the extra 1,1,1 ensures broadcastability when mixing with high dimensional tensors\n",
        "        #the minval and maxval ensures the sample is drawn from the range [0,1)\n",
        "        #purpose-used to interpolate between real and fake(generated) samples\n",
        "        epsilon = tf.random.uniform(shape=[batch_size,1,1,1],minval=0,maxval=1,dtype=tf.float16)\n",
        "\n",
        "\n",
        "        #interplated samples\n",
        "        interpolated_samples = epsilon * self.real_samples + (1-epsilon)*self.fake_samples\n",
        "\n",
        "\n",
        "        #train\n",
        "        with tf.GradientTape(watch_accessed_variables=True) as tape:\n",
        "            #watch\n",
        "            tape.watch(interpolated_samples)\n",
        "            #get the discriminator's output for the interpolated images\n",
        "            #remember that in WGAN-GP the discriminato now outputs logits\n",
        "            logits = self.discriminator(interpolated_samples,training=training)\n",
        "        #calculate the gradient\n",
        "        grad = tape.gradient(logits,interpolated_samples)\n",
        "        #calculate the l2 norm |f(x1)-f(x2)|<= |x1-x2|\n",
        "        grad_norm = tf.sqrt(tf.reduce_sum(tf.square(grad),axis=[1,2,3]))\n",
        "        #calculate the gradient penalty\n",
        "        grad_penalty = tf.reduce_mean((grad_norm-1.0)**2)\n",
        "        return grad_penalty\n",
        "\n",
        "    ##define a method which adds noise to each training sample before feeding it into the critic\n",
        "    def add_instance_noise(self, x: tf.Tensor, stddev: float=0.1) -> tf.Tensor:\n",
        "        \"\"\"Adds instance noise to the input tensor.#\n",
        "        A trick in GANS to ensure stability in training\"\"\"\n",
        "        noise = tf.random.normal(\n",
        "        tf.shape(x),       # ensure the same shape as input for consistency and avoidance of shape mismatch errors\n",
        "        mean=0.0,          # centered around zero\n",
        "        stddev=stddev, # controls the noise intensity-larger values mean more noise,makes the model more robust but affects generated image quality and vice versa\n",
        "        dtype=tf.float16,\n",
        "        )\n",
        "        return x + noise\n",
        "\n",
        "\n",
        "    #setup the train_step method, overrides the inbuilt one\n",
        "    def train_step(self,real_images,training:bool=True)->typing.Dict[str,tf.Tensor]:\n",
        "        batch_size = tf.shape(real_images)[0]\n",
        "        #noise generator\n",
        "        noise = tf.random.normal([batch_size,self.noise_dim], dtype=tf.float16)\n",
        "        #collect the grad penalties\n",
        "        gps = []\n",
        "\n",
        "        #train\n",
        "        #in WGAN-GP we want the discriminator to be more robust so we train it more\n",
        "        for _ in range(self.extra_train_steps):\n",
        "            with tf.GradientTape(watch_accessed_variables=True) as disc_tape:\n",
        "                disc_tape.watch(noise)\n",
        "                #generate images with generator\n",
        "                generated_images = self.generator(noise,training=training)\n",
        "                #add noise to the generated images\n",
        "                noise_to_gen_images = self.add_instance_noise(generated_images)\n",
        "                #get the discriminator to predict\n",
        "                pred_for_generic = self.discriminator(noise_to_gen_images,training=training)\n",
        "                #include noise in the discriminator prediction of the real images\n",
        "                pred_for_real = self.discriminator(self.add_instance_noise(real_images),training=training)\n",
        "\n",
        "                #calculate the WGAN-GP gp\n",
        "                gp = self.gradient_penalty( # Removed 'discriminator=self.discriminator' argument\n",
        "                                          real_samples = self.add_instance_noise(real_images),\n",
        "                                          fake_samples = noise_to_gen_images,training=True)\n",
        "                gps.append(gp)\n",
        "\n",
        "                #calculate the gradient with regards to the discriminator loss\n",
        "                #remember the gp is added to the discriminator with a minor scale factor\n",
        "                disc_loss = self.disc_loss(pred_for_generic,pred_for_real) + gp * self.gp_weight\n",
        "\n",
        "            #cmpute the discriminator gradients which comes after calculating the loss\n",
        "            disc_grad = disc_tape.gradient(disc_loss,self.discriminator.trainable_variables)\n",
        "\n",
        "            #update the weights accordingly with optimizer\n",
        "            self.disc_opt.apply_gradients(zip(disc_grad,self.discriminator.trainable_variables))\n",
        "\n",
        "        #time to train the generator\n",
        "        with tf.GradientTape() as gen_tape:\n",
        "            gen_tape.watch(noise)\n",
        "\n",
        "            #generate images with generator\n",
        "            generated_images = self.generator(noise,training=training)\n",
        "\n",
        "            #add noise before passing to the discriminator\n",
        "            noise_to_gen_images = self.add_instance_noise(generated_images)\n",
        "\n",
        "            #pass to the discriminator\n",
        "            fake_pred = self.discriminator(noise_to_gen_images,training=training)\n",
        "\n",
        "            #calcualate the generator loss\n",
        "            # The discriminator output influences the generator. the generator tries to minimize this loss\n",
        "            gen_loss = self.gen_loss(fake_pred)\n",
        "\n",
        "        #calculate gradients\n",
        "        gen_grad = gen_tape.gradient(gen_loss, self.generator.trainable_variables)\n",
        "\n",
        "        #update the weights accordingly with the optimizer\n",
        "        self.gen_opt.apply_gradients(zip(gen_grad,self.generator.trainable_variables))\n",
        "\n",
        "        ##update the metrics-this is from the compile() method from the class 'Model'\n",
        "        for metric in self.metrics:\n",
        "            metric.update_state(real_images,generated_images)\n",
        "\n",
        "        #update\n",
        "        results = {m.name:m.result() for m in self.metrics}\n",
        "        results.update({'d_loss':disc_loss,'g_loss':gen_loss,'gp':tf.reduce_mean(gps)})\n",
        "        return results"
      ],
      "metadata": {
        "id": "mJ6HfnZ0HhmX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wgan = WGAN_GP(discriminator=build_discriminator,generator=generator_model,random_noise_dim=100)"
      ],
      "metadata": {
        "id": "nhWvPCuK1RbD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#print model summary\n",
        "wgan.summary(show_trainable=True, expand_nested=True)"
      ],
      "metadata": {
        "id": "76M4HxSR1blB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##this code was retrieved from pylessons.org\n",
        "#it aids in visualizing and saving the gif and png of th model output\n",
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "import imageio\n",
        "class ResultsCallback(tf.keras.callbacks.Callback):\n",
        "    \"\"\"A callback that saves generated images after each epoch.\"\"\"\n",
        "    def __init__(\n",
        "            self,\n",
        "            noise_dim: int,\n",
        "            save_name:str,\n",
        "            results_path: str,\n",
        "            examples_to_generate: int=16,\n",
        "            grid_size: tuple=(4, 4),\n",
        "            spacing: int=5,\n",
        "            gif_size: tuple=(416, 416),\n",
        "            duration: float=0.1\n",
        "        ):\n",
        "        \"\"\" Initializes the ResultsCallback class.\n",
        "\n",
        "        Args:\n",
        "            noise_dim (int): The dimensionality of the noise vector that is inputted to the generator.\n",
        "            results_path (str): The path to the directory where the results will be saved.\n",
        "            examples_to_generate (int, optional): The number of images to generate and save. Defaults to 16.\n",
        "            grid_size (tuple, optional): The size of the grid to arrange the generated images. Defaults to (4, 4).\n",
        "            spacing (int, optional): The spacing between the generated images. Defaults to 5.\n",
        "            gif_size (tuple, optional): The size of the gif to be generated. Defaults to (416, 416).\n",
        "            duration (float, optional): The duration of each frame in the gif. Defaults to 0.1.\n",
        "        \"\"\"\n",
        "        super(ResultsCallback, self).__init__()\n",
        "        self.seed = tf.random.normal([examples_to_generate, noise_dim]) #for each image in the grid\n",
        "        self.results = []\n",
        "        self.results_path = results_path + '/results'\n",
        "        self.grid_size = grid_size\n",
        "        self.spacing = spacing\n",
        "        self.gif_size = gif_size\n",
        "        self.duration = duration\n",
        "        self.save_name = save_name\n",
        "\n",
        "        # create the results directory if it doesn't exist\n",
        "        os.makedirs(self.results_path, exist_ok=True)\n",
        "\n",
        "    def save_pred(self, epoch: int, results: list) -> None:\n",
        "        \"\"\" Saves the generated images as a grid and as a gif.\n",
        "\n",
        "        Args:\n",
        "            epoch (int): The current epoch.\n",
        "            results (list): A list of generated images.\n",
        "        \"\"\"\n",
        "        # construct an image from generated images with spacing between them using numpy\n",
        "        w, h , c = results[0].shape\n",
        "        # construct grid with self.grid_size\n",
        "        grid = np.zeros((self.grid_size[0] * w + (self.grid_size[0] - 1) * self.spacing, self.grid_size[1] * h + (self.grid_size[1] - 1) * self.spacing, c), dtype=np.uint8)\n",
        "        for i in range(self.grid_size[0]):\n",
        "            for j in range(self.grid_size[1]):\n",
        "                grid[i * (w + self.spacing):i * (w + self.spacing) + w, j * (h + self.spacing):j * (h + self.spacing) + h] = results[i * self.grid_size[1] + j]\n",
        "\n",
        "        # save the image\n",
        "        cv2.imwrite(f'{self.results_path}/img_{epoch}.png', grid)\n",
        "\n",
        "        # save image to memory resized to gif size\n",
        "        self.results.append(cv2.resize(grid, self.gif_size, interpolation=cv2.INTER_AREA))\n",
        "\n",
        "    def on_epoch_end(self, epoch: int, logs: dict=None) -> None:\n",
        "        \"\"\"Executes at the end of each epoch.\"\"\"\n",
        "        predictions = self.model.generator(self.seed, training=False)\n",
        "        predictions_uint8 = (predictions * 127.5 + 127.5).numpy().astype(np.uint8)\n",
        "        self.save_pred(epoch, predictions_uint8)\n",
        "\n",
        "    def on_train_end(self, logs=None) -> None:\n",
        "        \"\"\"Executes at the end of training.\"\"\"\n",
        "        # save the results as a gif with imageio\n",
        "\n",
        "        # Create a list of imageio image objects from the OpenCV images\n",
        "        imageio_images = [imageio.core.util.Image(image) for image in self.results]\n",
        "\n",
        "        # Write the imageio images to a GIF file\n",
        "        imageio.mimsave(self.results_path + f\"/{self.save_name}.gif\", imageio_images, duration=self.duration)"
      ],
      "metadata": {
        "id": "Bvr4vIVQ4EzN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#set callbacks for experiment control and tracking\n",
        "#for the first call back i will setup the Learning Rate scheduler\n",
        "#create a function to control learning rate scheduling\n",
        "def scheduler(epoch,lr):\n",
        "    \"\"\"Controls when and direction+magnitude of learning rate\"\"\"\n",
        "    if epoch % 2 == 0:\n",
        "        #update on even epochs\n",
        "        return float(lr * tf.exp(-0.1))\n",
        "    else:\n",
        "        return float(lr)\n",
        "#configure the learning rate scheduler\n",
        "lr_scheduler = LearningRateScheduler(schedule=scheduler,verbose=1)"
      ],
      "metadata": {
        "id": "jNdSqSU24aR6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##next callback will be the ReduceLROnPlateau\n",
        "lr_plateau = ReduceLROnPlateau(monitor='loss',patience=10,mode='auto',cooldown=0.1,min_delta=1e-4)"
      ],
      "metadata": {
        "id": "A61JPOyh6CWc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#create a function to train the model\n",
        "def train(model:tf.keras.models.Model,\n",
        "          epochs:int,\n",
        "          data,\n",
        "          noise_dim:int,\n",
        "          verbose:bool,\n",
        "          channel:int,\n",
        "          callbacks:typing.Union[tf.keras.callbacks],\n",
        "          save_model_name:str,\n",
        "          run_eagerly:bool=False,\n",
        "          optimizer:typing.Literal['Adam','SGD']='Adam',\n",
        "          download_path=False):\n",
        "    x_train = data\n",
        "\n",
        "    #incoming image shape\n",
        "    image_shape=(64,64,channel)\n",
        "\n",
        "    #set model path\n",
        "    model_path = os.path.join('/content/trained_model',f'{save_model_name}.h5')\n",
        "    parent_dir = os.path.dirname(model_path)\n",
        "\n",
        "    if not os.path.exists(parent_dir): # Check if parent directory exists\n",
        "        print(f'path {parent_dir} does not exist, creating.....')\n",
        "        os.makedirs(parent_dir,exist_ok=True)\n",
        "        print(f'path {parent_dir} successfully created')\n",
        "    else:\n",
        "        print(f'path {parent_dir} already exists')\n",
        "\n",
        "    # check to see if a directory with the model_path name already exists and remove it\n",
        "    if os.path.isdir(model_path):\n",
        "        print(f\"Warning: Directory '{model_path}' exists, removing it to save the model file.\")\n",
        "        #use shutil.rmtree to get rid of the directory\n",
        "        shutil.rmtree(model_path)\n",
        "\n",
        "    #configure model\n",
        "    model_used = model(discriminator=build_discriminator,generator=generator_model,random_noise_dim=noise_dim)\n",
        "\n",
        "    #setyp optimizer\n",
        "    genOpt = getattr(tf.keras.optimizers,optimizer)(learning_rate=0.0001,beta_1=0.99,beta_2=0.99,weight_decay=0.01)\n",
        "    discOpt = getattr(tf.keras.optimizers,optimizer)(learning_rate=0.0001,beta_1=0.99,beta_2=0.99,weight_decay=0.01)\n",
        "\n",
        "    #setup results callback\n",
        "    res_callbacks = ResultsCallback(noise_dim=noise_dim,save_name='flowers',results_path=os.path.dirname(model_path))\n",
        "\n",
        "    #compile\n",
        "    model_used.compile(disc_loss=discriminator_loss,\n",
        "            gen_loss=generator_loss,\n",
        "            disc_opt=discOpt,\n",
        "            gen_opt=genOpt,\n",
        "            run_eagerly=run_eagerly)\n",
        "    #esnure that callbacks is a list\n",
        "    if not isinstance(callbacks, (list,tuple)):\n",
        "        callbacks=[callbacks]\n",
        "\n",
        "    #add the res_callbacks to the list of callbacks\n",
        "    callbacks = list(callbacks)+[res_callbacks]\n",
        "\n",
        "    # using the tf.data.Dataset.from_generator to enable proper iteration through the content of the directory\n",
        "    dataset = tf.data.Dataset.from_generator(\n",
        "        lambda: (x_train[i] for i in range(len(x_train))), # Iterate through the DirectoryIterator\n",
        "        #force dataset to be of atensorpsec with the reuqiered shape\n",
        "        output_signature=tf.TensorSpec(shape=(None, image_shape[0], image_shape[1], image_shape[2]), dtype=tf.float16)\n",
        "    ).repeat()#repeat for every batch\n",
        "\n",
        "    #fit\n",
        "    results = model_used.fit(dataset,\n",
        "                             epochs=epochs,\n",
        "                             steps_per_epoch=20,\n",
        "                             verbose=verbose,\n",
        "                             callbacks=callbacks)\n",
        "\n",
        "    #save\n",
        "    model_used.save(model_path)\n",
        "    print(f'Model saved to {model_path}')\n",
        "\n",
        "    if download_path:\n",
        "        #download\n",
        "        files.download(model_path)\n",
        "\n",
        "    #return\n",
        "    return results"
      ],
      "metadata": {
        "id": "kqVp8eFrCQar"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#tensorboard\n",
        "import datetime\n",
        "import tensorboard\n",
        "#setup log directory\n",
        "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "#configure tensorboard as callback\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
        "#configure callbacks as a list\n",
        "callbacks = [lr_scheduler,lr_plateau,tensorboard_callback]"
      ],
      "metadata": {
        "id": "Y2bpXEudPF6e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##set mixed precision\n",
        "from keras import mixed_precision\n",
        "\n",
        "#set policy\n",
        "policy = mixed_precision.Policy('mixed_float16')\n",
        "\n",
        "mixed_precision.set_global_policy(policy)"
      ],
      "metadata": {
        "id": "Mn73ybDTX5Cd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#cuda\n",
        "tf.config.list_physical_devices('GPU')"
      ],
      "metadata": {
        "id": "dxXOzpwyZROz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##setup datapath\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_gen = ImageDataGenerator(\n",
        "    #preprocessing\n",
        "    preprocessing_function = lambda x:(x/127.5)-1.0,\n",
        "    #apply augmentation\n",
        "    horizontal_flip=True\n",
        ")\n",
        "\n",
        "#flow from the directory\n",
        "train_data = train_gen.flow_from_directory(directory='/content/image_data',\n",
        "                                           target_size=(64,64),\n",
        "                                           class_mode=None,\n",
        "                                           shuffle=True\n",
        "                                           )"
      ],
      "metadata": {
        "id": "rMop_FZzejA0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = train(model=WGAN_GP,\n",
        "                epochs=600,\n",
        "                data=train_data,\n",
        "                noise_dim=100,\n",
        "                verbose=True,\n",
        "                channel=3,\n",
        "                callbacks=callbacks,\n",
        "                save_model_name='wgan_model',\n",
        "                run_eagerly=False,\n",
        "                optimizer='Adam')"
      ],
      "metadata": {
        "id": "w_QE7vI5hdej"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results.history.keys()"
      ],
      "metadata": {
        "id": "6N5EACiWK-s5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir logs"
      ],
      "metadata": {
        "id": "o_yPsGHpLHYV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "the above chart gives a full overview of the model's performance during training. it includes the loss monitoring for both components of the GAN network namely the epoch_g_loss and the epoch_d_loss. These two metrics beloong to the generator and discriminator respectively. These can be seen training as expected with the loss for the generator gaining a downward trajectory implying its prowess to reducing its loss and improving its generative ability.the discriminator tries to maximize its loss implying that it is not being fooled and indicates to the generator to up its game."
      ],
      "metadata": {
        "id": "HdzocWE3XdX9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Great, now the model is trained on a simple dataset of flowers, lets check inference time and precision of the model to accurately generate an image based of a random noise vector. Remember that, the goal of the GAN model is to take a random noise vector usually sampled from a normal distribution and then produce an image that tries to mimic the training data which it was trained."
      ],
      "metadata": {
        "id": "14qqg6bmPD0B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##to pertorm inference, lets first load the saved model with the module and specific framework used\n",
        "##in this case Tensorflow\n",
        "import tensorflow as tf\n",
        "\n",
        "# Assuming the WGAN_GP class is defined in the current scope or imported\n",
        "#load the model from its saved path\n",
        "loaded_model = tf.keras.models.load_model(\n",
        "    filepath='/content/trained_model/wgan_model.h5',\n",
        "    compile=True,\n",
        "    custom_objects={'WGAN_GP': WGAN_GP(discriminator=build_discriminator,generator=generator_model,random_noise_dim=100)} # Add your custom model class here\n",
        ")"
      ],
      "metadata": {
        "id": "TigEhIRuXasA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#the error above is expected, it occurred because I did not perform an override of the basemodel's get_config and from_config\n",
        "#for serializing and deserializing the model respectively. Usually, to save a model, it has to be serialized for in order for it to be saved\n",
        "#and deserialized for it to be used. to do that i will do an override of the basemodel's config and use the tf.keras.utils.serialize_keras_objects() and\n",
        "#tf.keras.deserialize_keras_object()"
      ],
      "metadata": {
        "id": "52QpmmWXXapT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bzukCpszXamp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cVVvpHAcXajm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}